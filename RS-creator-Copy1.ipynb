{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695dd8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import xlrd\n",
    "import xlutils.copy\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import camelot\n",
    "import tabula\n",
    "from pyexcel.cookbook import merge_all_to_a_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d23505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getOutCell(outSheet, colIndex, rowIndex):\n",
    "    \"\"\" HACK: Extract the internal xlwt cell representation. \"\"\"\n",
    "    row = outSheet._Worksheet__rows.get(rowIndex)\n",
    "    if not row: return None\n",
    "\n",
    "    cell = row._Row__cells.get(colIndex)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc880728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOutCell(outSheet, col, row, value):\n",
    "    \"\"\" Change cell value without changing formatting. \"\"\"\n",
    "    # HACK to retain cell style.\n",
    "    previousCell = _getOutCell(outSheet, col, row)\n",
    "    # END HACK, PART I\n",
    "\n",
    "    outSheet.write(row, col, value)\n",
    "\n",
    "    # HACK, PART II\n",
    "    if previousCell:\n",
    "        newCell = _getOutCell(outSheet, col, row)\n",
    "        if newCell:\n",
    "            newCell.xf_idx = previousCell.xf_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a5482b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_results (df_peak, compound, average_area, constant_1, constant_2, unit):\n",
    "    base_rrt = float(df_peak['Ret. Time'][df_peak['Name'].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0])\n",
    "    rrt_master = []\n",
    "    impurity_master = []\n",
    "    rrf_master = []\n",
    "    for index, row in df_peak.iterrows():\n",
    "        name =row[1]\n",
    "        if(name.lower() == compound.lower()):\n",
    "            impurity_master.append(0)\n",
    "            rrt_master.append(1)\n",
    "            rrf_master.append(0)\n",
    "            continue\n",
    "        if(name == np.nan or name == ''):\n",
    "            continue\n",
    "#             impurity_master.append(0)\n",
    "#             rrt_master.append(0)\n",
    "            \n",
    "        area = float(row[3])\n",
    "        rrf_cond_1 = df_rrf['Compound'].str.contains(compound, flags = re.IGNORECASE)\n",
    "        rrf_cond_2 = df_rrf['Impurity/Active Name'].str.contains(name, flags = re.IGNORECASE)\n",
    "        rrf = df_rrf['RRF'][rrf_cond_1 & rrf_cond_2].values.tolist()\n",
    "        rrt = float(row[2])\n",
    "        \n",
    "        if(not(rrf)):\n",
    "            print(\"ignoring {}\".format(name))\n",
    "            impurity_master.append(0)\n",
    "            rrt_res = round(rrt/base_rrt, ndigits=2)\n",
    "            rrt_master.append(rrt_res)\n",
    "            rrf_master.append(0)\n",
    "            continue\n",
    "            \n",
    "        rrf = float(rrf[0])\n",
    "        impurity = round((area/average_area) * constant_1 * constant_2 * (unit/rrf), ndigits=2)\n",
    "        rrt_res = round(rrt/base_rrt, ndigits=2)\n",
    "        impurity_master.append(impurity)\n",
    "        rrt_master.append(rrt_res)\n",
    "        rrf_master.append(rrf)\n",
    "\n",
    "    return impurity_master, rrt_master, rrf_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbe0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_row_to_top(df, index_to_shift):\n",
    "    idx = df.index.tolist()\n",
    "    idx.remove(index_to_shift)\n",
    "    df = df.reindex([index_to_shift] + idx)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c45417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_extratcor(tables, headers):\n",
    "    df_result_table =''\n",
    "    result_tables = []\n",
    "    for table in tables:\n",
    "        df_table = table.df\n",
    "        search = df_table.where(df_table==headers[0]).dropna(how='all').dropna(axis=1)\n",
    "        inx = list(search.index)\n",
    "        if(inx):\n",
    "            inx= inx[0]\n",
    "            new_header = df_table.iloc[inx]\n",
    "            new_start_inx = inx+1\n",
    "            df_table = df_table[new_start_inx:] \n",
    "            df_table.columns = new_header\n",
    "            df_table = df_table[headers]\n",
    "            result_tables.append(df_table)\n",
    "        else:\n",
    "            continue\n",
    "    df_result_table = pd.concat(result_tables, ignore_index=True)\n",
    "    return df_result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c22526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rs_sheet(output_sheet, df_area_table, df_peak_table, sample_input_list):\n",
    "    average_area = float(df_area_table[\"Area\"][df_area_table[\"Title\"] == \"Average\"].values.tolist()[0])\n",
    "    area_input = list(df_area_table['Area'])\n",
    "    \n",
    "    #poject name\n",
    "    setOutCell(output_sheet, 2, 3, '')\n",
    "    #Date\n",
    "    setOutCell(output_sheet, 2, 4, '')\n",
    "    #Method\n",
    "    setOutCell(output_sheet, 2, 5, '')\n",
    "    # WS ID No.\n",
    "    setOutCell(output_sheet, 1, 9, '')\n",
    "    # potency\n",
    "    setOutCell(output_sheet, 3, 9, input_list[-1])\n",
    "    # use before date\n",
    "    setOutCell(output_sheet, 5, 9, '')\n",
    "    # Average area\n",
    "    setOutCell(output_sheet, 7, 9, average_area)\n",
    "    # std_wt\n",
    "    setOutCell(output_sheet, 2, 10, input_list[0])\n",
    "    #  v1\n",
    "    setOutCell(output_sheet, 2, 11, input_list[1])\n",
    "    # v2\n",
    "    setOutCell(output_sheet, 4, 10, input_list[2])\n",
    "    #  v3\n",
    "    setOutCell(output_sheet, 4, 11, input_list[3])\n",
    "    #  v4\n",
    "    setOutCell(output_sheet, 6, 10,  input_list[4])\n",
    "    # v5\n",
    "    setOutCell(output_sheet, 6, 11, input_list[5])\n",
    "    # v6\n",
    "    setOutCell(output_sheet, 8, 10, input_list[6])\n",
    "    # v7\n",
    "    setOutCell(output_sheet, 8, 11, input_list[7])\n",
    "    # factor\n",
    "    setOutCell(output_sheet, 9, 10, input_list[8])\n",
    "    # factor\n",
    "    setOutCell(output_sheet, 9, 11, input_list[9])\n",
    "    # AR NO\n",
    "    setOutCell(output_sheet, 1, 14, '')\n",
    "    # Batch NO\n",
    "    setOutCell(output_sheet, 3, 14, '')\n",
    "    # Condition\n",
    "    setOutCell(output_sheet, 4, 14, '')\n",
    "    # Label Claim\n",
    "    setOutCell(output_sheet, 5, 14, sample_input_list[8])\n",
    "    # per unit\n",
    "    setOutCell(output_sheet, 7, 14, sample_input_list[9])\n",
    "    # sample_wt\n",
    "    setOutCell(output_sheet, 2, 15, sample_input_list[0])\n",
    "    #  v1\n",
    "    setOutCell(output_sheet, 2, 16, sample_input_list[1])\n",
    "    # v2\n",
    "    setOutCell(output_sheet, 4, 15, sample_input_list[2])\n",
    "    #  v3\n",
    "    setOutCell(output_sheet, 4, 16, sample_input_list[3])\n",
    "    #  v4\n",
    "    setOutCell(output_sheet, 6, 15, sample_input_list[4])\n",
    "    # v5\n",
    "    setOutCell(output_sheet, 6, 16, sample_input_list[5])\n",
    "    # v6\n",
    "    setOutCell(output_sheet, 8, 15, sample_input_list[6])\n",
    "    # v7\n",
    "    setOutCell(output_sheet, 8, 16, sample_input_list[7])\n",
    "#     areas\n",
    "    setOutCell(output_sheet, 12, 5, area_input[0])\n",
    "    setOutCell(output_sheet, 12, 6, area_input[1])\n",
    "    setOutCell(output_sheet, 12, 7, area_input[2])\n",
    "    setOutCell(output_sheet, 12, 8, area_input[3])\n",
    "    setOutCell(output_sheet, 12, 9, area_input[4])\n",
    "    setOutCell(output_sheet, 12, 10, area_input[5])\n",
    "    setOutCell(output_sheet, 12, 11, area_input[6])\n",
    "    setOutCell(output_sheet, 12, 12, area_input[7])\n",
    "    setOutCell(output_sheet, 12, 13, area_input[8])\n",
    "#   Impurity table  \n",
    "    table_row = 20\n",
    "    for index, row in df_peak_table.iterrows():\n",
    "        if(table_row > 60):\n",
    "            break\n",
    "        setOutCell(output_sheet, 1, table_row, row[0])\n",
    "        setOutCell(output_sheet, 2, table_row, row[1])\n",
    "        setOutCell(output_sheet, 3, table_row, row[2])\n",
    "        setOutCell(output_sheet, 4, table_row, row[3])\n",
    "        setOutCell(output_sheet, 5, table_row, row[4])\n",
    "        setOutCell(output_sheet, 6, table_row, row[5])\n",
    "        table_row +=1\n",
    "\n",
    "    sum_of_impurities = round(df_peak_table[\"% w/w\"].sum(), ndigits=2)\n",
    "    setOutCell(output_sheet, 6, 62, sum_of_impurities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf06234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_report_creation(compound, input_lits):\n",
    "    sample_wt = df_sample_prep['vials'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v1 = df_sample_prep['v1'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v2 = df_sample_prep['v2'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v3 = df_sample_prep['v3'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v4 = df_sample_prep['v4'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v5 = df_sample_prep['v5'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v6 = df_sample_prep['v6'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    sample_v7 = df_sample_prep['v7'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    label_claim = df_sample_prep['label claim'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "    unit = df_sample_prep['per unit'][df_sample_prep[\"Compound\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0]\n",
    "\n",
    "    constant_1 = (input_list[0]/input_list[1]) * (input_list[2]/input_list[3]) * (input_list[4]/input_list[5])*(input_list[6]/input_list[7]) * (input_list[8]/input_list[9])\n",
    "    constant_2 = (sample_v1/sample_wt) * (sample_v3/sample_v2) * (sample_v5/sample_v4) * (sample_v7/sample_v6) * (input_list[10]/label_claim)\n",
    "\n",
    "    # peak table extratcion\n",
    "    tables = camelot.read_pdf(chrom_input, pages= 'all',flavor='stream')\n",
    "    df_peak_table = table_extratcor(tables, chrom_headers)\n",
    "    inx_to_shift = df_peak_table[df_peak_table[\"Name\"].str.contains(compound, flags = re.IGNORECASE)].index[0]\n",
    "    df_peak_table = shift_row_to_top(df_peak_table, inx_to_shift)\n",
    "    cond_1 = df_peak_table[\"Name\"] == ''\n",
    "    cond_2 = df_peak_table[\"Name\"] == np.nan\n",
    "    inxs_to_remove = df_peak_table[cond_1 | cond_2].index\n",
    "    df_peak_table = df_peak_table.drop(inxs_to_remove)\n",
    "\n",
    "    # area table extraction\n",
    "    tables = camelot.read_pdf(area_input, pages= 'all',flavor='stream')\n",
    "    df_area_table = table_extratcor(tables, area_headers)\n",
    "    df_area_table = df_area_table[['Title', 'Area']]\n",
    "    average_area = float(df_area_table[\"Area\"][df_area_table[\"Title\"] == \"Average\"].values.tolist()[0])\n",
    "\n",
    "    # impurity calculation\n",
    "    impurities, rrts, rrfs = calc_results(df_peak_table, compound, average_area, constant_1, constant_2, unit)\n",
    "    df_peak_table['RRT'] = rrts\n",
    "    df_peak_table['RRF'] = rrfs\n",
    "    df_peak_table[\"% w/w\"] = impurities\n",
    "    df_peak_table = df_peak_table[['Name', 'Ret. Time','RRT', 'RRF', 'Area', '% w/w']]\n",
    "\n",
    "    # writing to output sheet\n",
    "    sample_input_list = [sample_wt, sample_v1, sample_v2, sample_v3, sample_v4, sample_v5, sample_v6, sample_v7, label_claim, unit]\n",
    "    fill_rs_sheet(rs_template_sheet, df_area_table, df_peak_table, sample_input_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09869d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bumetanide\n",
    "# Acyclovir\n",
    "# Famotidine\n",
    "# ketorolacTromethamine\n",
    "# LabetalolHCl\n",
    "# input_list = [20.48,20,1,100,5,20,1,1,1,1,99.0]\n",
    "\n",
    "# compound = input(\"Enter the compund name [As mentioned in the chromatogram] \")\n",
    "compound = 'Acyclovir'\n",
    "input_list = [50.43,100,5,50,5,50,1,1,1,1,94.4]\n",
    "# input data sources\n",
    "df_rrf = pd.read_excel(os.path.join(os.getcwd(), 'data', 'Templates', 'RRF-template.xlsx'))\n",
    "df_sample_prep = pd.read_excel(os.path.join(os.getcwd(), 'data', 'Templates', 'Sample Preparation.xlsx'))\n",
    "chrom_input = os.path.join(os.getcwd(), \"data\", \"chromatograms\", \"{}-chromatogram.pdf\".format(compound))\n",
    "area_input = os.path.join(os.getcwd(), \"data\", \"Areas\", \"{}-areas.pdf\".format(compound))\n",
    "\n",
    "# input_list = [0]*11\n",
    "# input_list[0] = float(input(\"Enter the Weight taken \"))\n",
    "# input_list[1] = float(input(\"Enter the standard preparation v1 \")) \n",
    "# input_list[2] = float(input(\"Enter the standard preparation v2 \")) \n",
    "# input_list[3] = float(input(\"Enter the standard preparation v3 \")) \n",
    "# input_list[4] = float(input(\"Enter the standard preparation v4 \")) \n",
    "# input_list[5] = float(input(\"Enter the standard preparation v5 \")) \n",
    "# input_list[6] = float(input(\"Enter the standard preparation v6 \")) \n",
    "# input_list[7] = float(input(\"Enter the standard preparation v7 \")) \n",
    "# input_list[8] = float(input(\"Enter the standard preparation factor 1 \")) \n",
    "# input_list[9] = float(input(\"Enter the standard preparation factor 2 \")) \n",
    "# input_list[10] = float(input(\"Enter the standard preparation Potency \")) \n",
    " \n",
    "\n",
    "chrom_headers = ['Peak#','Name','Ret. Time','Area','Area%','RRT']\n",
    "area_headers = ['Title', 'Ret. Time', 'Area', 'Area%', 'NTP', 'Tailing Factor']\n",
    "\n",
    "\n",
    "\n",
    "# Output sheet\n",
    "rs_template_input = xlrd.open_workbook(os.path.join(os.getcwd(), \"data\", \"Templates\",'RS-template.xls'), formatting_info=True)\n",
    "rs_template = xlutils.copy.copy(rs_template_input)\n",
    "rs_template_sheet = rs_template.get_sheet(0)\n",
    "\n",
    "initiate_report_creation(compound, input_list)\n",
    "rs_template.save(os.path.join(os.getcwd(), \"data\", 'output', '{}-RS.xls'.format(compound)))\n",
    "print(\"Report saved successfully, check Output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Name','Ret. Time','Area']\n",
    "headers = ['Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_input = os.path.join(os.getcwd(), \"data\", \"chromatograms\", \"Famotidine-chromatogram.pdf\".format(compound))\n",
    "area_input = os.path.join(os.getcwd(), \"data\", \"areas\", \"Acyclovir-areas.pdf\".format(compound))\n",
    "tables = camelot.read_pdf(chrom_input, pages= 'all',flavor='stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_table =''\n",
    "result_tables = []\n",
    "for table in tables:\n",
    "    df_table = table.df\n",
    "    search = df_table.where(df_table==headers[0]).dropna(how='all').dropna(axis=1)\n",
    "    inx = list(search.index)\n",
    "    if(inx):\n",
    "        inx= inx[0]\n",
    "        new_header = df_table.iloc[inx]\n",
    "        new_start_inx = inx+1\n",
    "        df_table = df_table[new_start_inx:] \n",
    "        df_table.columns = new_header\n",
    "        df_table = df_table[headers]\n",
    "        result_tables.append(df_table)\n",
    "    else:\n",
    "        continue\n",
    "df_result_table = pd.concat(result_tables, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6732d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_table = df_result_table.drop_duplicates(keep='first')\n",
    "df_peak_table = df_result_table\n",
    "inx_to_shift = df_peak_table[df_peak_table[\"Name\"].str.contains(compound, flags = re.IGNORECASE)].index[0]\n",
    "df_peak_table = shift_row_to_top(df_peak_table, inx_to_shift)\n",
    "cond_1 = df_peak_table[\"Name\"] == ''\n",
    "cond_2 = df_peak_table[\"Name\"] == np.nan\n",
    "inxs_to_remove = df_peak_table[cond_1 | cond_2].index\n",
    "df_peak_table = df_peak_table.drop(inxs_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8369445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peak_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d681c8a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compound = 'Lidocaine HCL'\n",
    "# headers = ['Name','Area']\n",
    "headers = ['Area']\n",
    "chrom_input = os.path.join(os.getcwd(), \"data\", \"Assay\", \"Lidocaine HCL\", \"Lidocaine HCL-areas.pdf\")\n",
    "tables = camelot.read_pdf(chrom_input, pages= 'all', line_scale =30)\n",
    "# tables = camelot.read_pdf(chrom_input, pages= 'all', flavour = 'stream')\n",
    "df_peak_table = table_extratcor(tables, headers)\n",
    "df_peak_table = df_peak_table.drop_duplicates(keep=\"first\")\n",
    "# base_rt = float(df_peak_table['Ret. Time'][df_peak_table[\"Name\"].str.contains(compound, flags = re.IGNORECASE)].values.tolist()[0])\n",
    "# compound_row = df_peak_table[df_peak_table[\"Name\"].str.contains(compound, flags = re.IGNORECASE)].index\n",
    "# df_peak_table = df_peak_table.drop(compound_row)\n",
    "# cond_1 = df_peak_table[\"Name\"] == ''\n",
    "# cond_2 = df_peak_table[\"Name\"] == np.nan\n",
    "# inxs_to_remove = df_peak_table[cond_1 | cond_2].index\n",
    "# df_peak_table = df_peak_table.drop(inxs_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e02e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a939b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18c4eee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>Ret. Time</td>\n",
       "      <td>Area</td>\n",
       "      <td>Area%</td>\n",
       "      <td>NTP</td>\n",
       "      <td>Tailing Factor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Solution_01.lcd</td>\n",
       "      <td>10.33</td>\n",
       "      <td>6258219</td>\n",
       "      <td>76.512</td>\n",
       "      <td>16375</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Solution_02.lcd</td>\n",
       "      <td>10.34</td>\n",
       "      <td>6255624</td>\n",
       "      <td>76.515</td>\n",
       "      <td>16385</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Standard Solution_03.lcd</td>\n",
       "      <td>10.33</td>\n",
       "      <td>6255154</td>\n",
       "      <td>76.515</td>\n",
       "      <td>16397</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard Solution_04.lcd</td>\n",
       "      <td>10.33</td>\n",
       "      <td>6256060</td>\n",
       "      <td>76.525</td>\n",
       "      <td>16406</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Standard Solution_05.lcd</td>\n",
       "      <td>10.34</td>\n",
       "      <td>6259263</td>\n",
       "      <td>76.520</td>\n",
       "      <td>16410</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Standard Solution_06.lcd</td>\n",
       "      <td>10.34</td>\n",
       "      <td>6257214</td>\n",
       "      <td>76.522</td>\n",
       "      <td>16386</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Average</td>\n",
       "      <td>10.34</td>\n",
       "      <td>6256922</td>\n",
       "      <td>76.518</td>\n",
       "      <td>16393</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>%RSD</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Standard Deviation</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>14</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1        2       3      4               5\n",
       "0                     Title  Ret. Time     Area   Area%    NTP  Tailing Factor\n",
       "1  Standard Solution_01.lcd      10.33  6258219  76.512  16375            1.07\n",
       "2  Standard Solution_02.lcd      10.34  6255624  76.515  16385            1.07\n",
       "3  Standard Solution_03.lcd      10.33  6255154  76.515  16397            1.07\n",
       "4  Standard Solution_04.lcd      10.33  6256060  76.525  16406            1.07\n",
       "5  Standard Solution_05.lcd      10.34  6259263  76.520  16410            1.07\n",
       "6  Standard Solution_06.lcd      10.34  6257214  76.522  16386            1.07\n",
       "7                   Average      10.34  6256922  76.518  16393            1.07\n",
       "8                      %RSD       0.01     0.03    0.01   0.08            0.02\n",
       "9        Standard Deviation       0.00     1600   0.005     14              --"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[7].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b972388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_peak_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5571897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
